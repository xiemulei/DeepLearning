# è®­ç»ƒ (Training)

æˆ‘ä»¬ç°åœ¨å‡†å¤‡ç¼–å†™å¿…è¦çš„ä»£ç æ¥åœ¨ MNIST æ•°æ®é›†ä¸Šè®­ç»ƒæˆ‘ä»¬çš„æ¨¡å‹ã€‚æˆ‘ä»¬å°†åœ¨æ–‡ä»¶ `src/training.rs` ä¸­å®šä¹‰æ­¤è®­ç»ƒéƒ¨åˆ†çš„ä»£ç ã€‚

é™¤äº†ç®€å•çš„å¼ é‡ï¼Œæ¨¡å‹åº”è¯¥è¾“å‡ºä¸€ä¸ªå¯ä»¥è¢«å­¦ä¹ å™¨ç†è§£çš„é¡¹ç›®ï¼Œè¿™æ˜¯ä¸€ä¸ªè´Ÿè´£å°†ä¼˜åŒ–å™¨åº”ç”¨äºæ¨¡å‹çš„ç»“æ„ä½“ã€‚è¾“å‡ºç»“æ„ä½“ç”¨äºè®­ç»ƒæœŸé—´è®¡ç®—çš„æ‰€æœ‰æŒ‡æ ‡ã€‚å› æ­¤ï¼Œå®ƒåº”è¯¥åŒ…å«è®¡ç®—ä»»åŠ¡æ‰€éœ€çš„ä»»ä½•æŒ‡æ ‡çš„å¿…è¦ä¿¡æ¯ã€‚

Burn æä¾›ä¸¤ä¸ªåŸºæœ¬è¾“å‡ºç±»å‹ï¼š`ClassificationOutput` å’Œ `RegressionOutput`ã€‚å®ƒä»¬å®ç°äº†å¿…è¦çš„ trait ä»¥ä¾¿ä¸æŒ‡æ ‡ä¸€èµ·ä½¿ç”¨ã€‚å¯ä»¥åˆ›å»ºè‡ªå·±çš„é¡¹ç›®ï¼Œä½†è¿™è¶…å‡ºäº†æœ¬æŒ‡å—çš„èŒƒå›´ã€‚

ç”±äº MNIST ä»»åŠ¡æ˜¯ä¸€ä¸ªåˆ†ç±»é—®é¢˜ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ `ClassificationOutput` ç±»å‹ã€‚

```rust
use crate::{
    data::{MnistBatch, MnistBatcher},
    model::{Model, ModelConfig},
};
use burn::{
    data::{dataloader::DataLoaderBuilder, dataset::vision::MnistDataset},
    nn::loss::CrossEntropyLossConfig,
    optim::AdamConfig,
    prelude::*,
    record::CompactRecorder,
    tensor::backend::AutodiffBackend,
    train::{
        metric::{AccuracyMetric, LossMetric},
        ClassificationOutput, LearnerBuilder, TrainOutput, TrainStep, ValidStep,
    },
};

impl<B: Backend> Model<B> {
    pub fn forward_classification(
        &self,
        images: Tensor<B, 3>,
        targets: Tensor<B, 1, Int>,
    ) -> ClassificationOutput<B> {
        let output = self.forward(images);
        let loss = CrossEntropyLossConfig::new()
            .init(&output.device())
            .forward(output.clone(), targets.clone());

        ClassificationOutput::new(loss, output, targets)
    }
}
```

ä»å‰é¢çš„ä»£ç å—å¯ä»¥æ˜æ˜¾çœ‹å‡ºï¼Œæˆ‘ä»¬é‡‡ç”¨äº¤å‰ç†µæŸå¤±æ¨¡å—è¿›è¡ŒæŸå¤±è®¡ç®—ï¼Œä¸åŒ…å«ä»»ä½•å¡«å……æ ‡è®°ã€‚ç„¶åæˆ‘ä»¬è¿”å›åŒ…å«æŸå¤±ã€æ‰€æœ‰ logits çš„è¾“å‡ºå¼ é‡å’Œç›®æ ‡çš„åˆ†ç±»è¾“å‡ºã€‚

è¯·æ³¨æ„ï¼Œå¼ é‡æ“ä½œæ¥æ”¶æ‹¥æœ‰çš„å¼ é‡ä½œä¸ºè¾“å…¥ã€‚ä¸ºäº†é‡ç”¨å¼ é‡å¤šæ¬¡ï¼Œæ‚¨éœ€è¦ä½¿ç”¨ `clone()` å‡½æ•°ã€‚æ— éœ€æ‹…å¿ƒï¼›è¿™ä¸ªè¿‡ç¨‹ä¸ä¼šæ¶‰åŠå¼ é‡æ•°æ®çš„å®é™…å¤åˆ¶ã€‚ç›¸åï¼Œå®ƒåªä¼šæŒ‡ç¤ºå¼ é‡è¢«å¤šä¸ªå®ä¾‹ä½¿ç”¨ï¼Œè¿™æ„å‘³ç€æŸäº›æ“ä½œä¸ä¼šå°±åœ°æ‰§è¡Œã€‚æ€»ä¹‹ï¼Œæˆ‘ä»¬çš„ API è®¾è®¡ä¸ºæ‹¥æœ‰å¼ é‡ä»¥ä¼˜åŒ–æ€§èƒ½ã€‚

æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å°†ç»§ç»­å®ç°æˆ‘ä»¬æ¨¡å‹çš„è®­ç»ƒå’ŒéªŒè¯æ­¥éª¤ã€‚

```rust
use crate::{
    data::{MnistBatch, MnistBatcher},
    model::{Model, ModelConfig},
};
use burn::{
    data::{dataloader::DataLoaderBuilder, dataset::vision::MnistDataset},
    nn::loss::CrossEntropyLossConfig,
    optim::AdamConfig,
    prelude::*,
    record::CompactRecorder,
    tensor::backend::AutodiffBackend,
    train::{
        metric::{AccuracyMetric, LossMetric},
        ClassificationOutput, LearnerBuilder, TrainOutput, TrainStep, ValidStep,
    },
};

impl<B: Backend> Model<B> {
    pub fn forward_classification(
        &self,
        images: Tensor<B, 3>,
        targets: Tensor<B, 1, Int>,
    ) -> ClassificationOutput<B> {
        let output = self.forward(images);
        let loss = CrossEntropyLossConfig::new()
            .init(&output.device())
            .forward(output.clone(), targets.clone());

        ClassificationOutput::new(loss, output, targets)
    }
}

impl<B: AutodiffBackend> TrainStep<MnistBatch<B>, ClassificationOutput<B>> for Model<B> {
    fn step(&self, batch: MnistBatch<B>) -> TrainOutput<ClassificationOutput<B>> {
        let item = self.forward_classification(batch.images, batch.targets);

        TrainOutput::new(self, item.loss.backward(), item)
    }
}

impl<B: Backend> ValidStep<MnistBatch<B>, ClassificationOutput<B>> for Model<B> {
    fn step(&self, batch: MnistBatch<B>) -> ClassificationOutput<B> {
        self.forward_classification(batch.images, batch.targets)
    }
}
```

åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬åœ¨ `TrainStep` å’Œ `ValidStep` ä¸­å°†è¾“å…¥å’Œè¾“å‡ºç±»å‹å®šä¹‰ä¸ºæ³›å‹å‚æ•°ã€‚æˆ‘ä»¬å°†è°ƒç”¨å®ƒä»¬ï¼Œè¾“å…¥ä¸º `MnistBatch`ï¼Œè¾“å‡ºä¸º `ClassificationOutput`ã€‚åœ¨è®­ç»ƒæ­¥éª¤ä¸­ï¼Œæ¢¯åº¦çš„è®¡ç®—å¾ˆç®€å•ï¼Œåªéœ€è¦å¯¹æŸå¤±ç®€å•è°ƒç”¨ `backward()`ã€‚è¯·æ³¨æ„ï¼Œä¸ PyTorch ç›¸åï¼Œæ¢¯åº¦ä¸æ˜¯ä¸æ¯ä¸ªå¼ é‡å‚æ•°ä¸€èµ·å­˜å‚¨ï¼Œè€Œæ˜¯ç”±åå‘ä¼ æ’­è¿”å›ï¼Œå¦‚ï¼š`let gradients = loss.backward();`ã€‚å‚æ•°çš„æ¢¯åº¦å¯ä»¥é€šè¿‡ grad å‡½æ•°è·å¾—ï¼š`let grad = tensor.grad(&gradients);`ã€‚è™½ç„¶åœ¨ä½¿ç”¨å­¦ä¹ å™¨ç»“æ„å’Œä¼˜åŒ–å™¨æ—¶ä¸æ˜¯å¿…éœ€çš„ï¼Œä½†åœ¨è°ƒè¯•æˆ–ç¼–å†™è‡ªå®šä¹‰è®­ç»ƒå¾ªç¯æ—¶å¯èƒ½éå¸¸æœ‰ç”¨ã€‚è®­ç»ƒæ­¥éª¤å’ŒéªŒè¯æ­¥éª¤ä¹‹é—´çš„åŒºåˆ«ä¹‹ä¸€æ˜¯å‰è€…éœ€è¦åç«¯å®ç° `AutodiffBackend` è€Œä¸ä»…ä»…æ˜¯ `Backend`ã€‚å¦åˆ™ï¼Œ`backward` å‡½æ•°ä¸å¯ç”¨ï¼Œå› ä¸ºåç«¯ä¸æ”¯æŒè‡ªåŠ¨å¾®åˆ†ã€‚æˆ‘ä»¬ç¨åå°†çœ‹åˆ°å¦‚ä½•åˆ›å»ºæ”¯æŒè‡ªåŠ¨å¾®åˆ†çš„åç«¯ã€‚

<details>
<summary><strong>ğŸ¦€ æ–¹æ³•å®šä¹‰ä¸­çš„æ³›å‹ç±»å‹çº¦æŸ</strong></summary>
<p>è™½ç„¶æ³›å‹æ•°æ®ç±»å‹ã€trait å’Œ trait çº¦æŸå·²ç»åœ¨æœ¬æŒ‡å—çš„å‰é¢éƒ¨åˆ†ä»‹ç»è¿‡ï¼Œä½†å‰é¢çš„ä»£ç ç‰‡æ®µå¯èƒ½ä¸€å¼€å§‹å¾ˆéš¾ç†è§£ã€‚</p>

<p>åœ¨ä¸Šé¢çš„ç¤ºä¾‹ä¸­ï¼Œæˆ‘ä»¬ä¸º `Model` ç»“æ„ä½“å®ç° `TrainStep` å’Œ `ValidStep` traitï¼Œè¯¥ç»“æ„ä½“å¯¹äº `Backend` trait æ˜¯æ³›å‹çš„ï¼Œå¦‚å‰æ‰€è¿°ã€‚è¿™äº› trait ç”± `burn::train` æä¾›ï¼Œå¹¶å®šä¹‰äº†ä¸€ä¸ªåº”è¯¥ä¸ºæ‰€æœ‰ç»“æ„ä½“å®ç°çš„é€šç”¨ `step` æ–¹æ³•ã€‚ç”±äº trait å¯¹äºè¾“å…¥å’Œè¾“å‡ºç±»å‹æ˜¯æ³›å‹çš„ï¼Œtrait å®ç°å¿…é¡»æŒ‡å®šä½¿ç”¨çš„å…·ä½“ç±»å‹ã€‚è¿™å°±æ˜¯å‡ºç°é¢å¤–ç±»å‹çº¦æŸçš„åœ°æ–¹ `<MnistBatch<B>, ClassificationOutput<B>>`ã€‚æ­£å¦‚æˆ‘ä»¬ä¹‹å‰çœ‹åˆ°çš„ï¼Œæ‰¹æ¬¡çš„å…·ä½“è¾“å…¥ç±»å‹æ˜¯ `MnistBatch`ï¼Œå‰å‘ä¼ æ’­çš„è¾“å‡ºæ˜¯ `ClassificationOutput`ã€‚`step` æ–¹æ³•ç­¾ååŒ¹é…å…·ä½“çš„è¾“å…¥å’Œè¾“å‡ºç±»å‹ã€‚</p>

<p>æœ‰å…³åœ¨å®šä¹‰æ–¹æ³•æ—¶æ³›å‹ç±»å‹çš„çº¦æŸçš„æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·æŸ¥çœ‹ Rust Book ä¸­çš„<a href="https://doc.rust-lang.org/book/ch10-01-syntax.html#in-method-definitions">æœ¬èŠ‚</a>ã€‚</p>
</details><br>

è®©æˆ‘ä»¬ç»§ç»­å»ºç«‹å®é™…çš„è®­ç»ƒé…ç½®ã€‚

```rust
use crate::{
    data::{MnistBatch, MnistBatcher},
    model::{Model, ModelConfig},
};
use burn::{
    data::{dataloader::DataLoaderBuilder, dataset::vision::MnistDataset},
    nn::loss::CrossEntropyLossConfig,
    optim::AdamConfig,
    prelude::*,
    record::CompactRecorder,
    tensor::backend::AutodiffBackend,
    train::{
        ClassificationOutput, LearnerBuilder, LearningStrategy, TrainOutput, TrainStep, ValidStep,
        metric::{AccuracyMetric, LossMetric},
    },
};

impl<B: Backend> Model<B> {
    pub fn forward_classification(
        &self,
        images: Tensor<B, 3>,
        targets: Tensor<B, 1, Int>,
    ) -> ClassificationOutput<B> {
        let output = self.forward(images);
        let loss = CrossEntropyLossConfig::new()
            .init(&output.device())
            .forward(output.clone(), targets.clone());

        ClassificationOutput::new(loss, output, targets)
    }
}

impl<B: AutodiffBackend> TrainStep<MnistBatch<B>, ClassificationOutput<B>> for Model<B> {
    fn step(&self, batch: MnistBatch<B>) -> TrainOutput<ClassificationOutput<B>> {
        let item = self.forward_classification(batch.images, batch.targets);

        TrainOutput::new(self, item.loss.backward(), item)
    }
}

impl<B: Backend> ValidStep<MnistBatch<B>, ClassificationOutput<B>> for Model<B> {
    fn step(&self, batch: MnistBatch<B>) -> ClassificationOutput<B> {
        self.forward_classification(batch.images, batch.targets)
    }
}

#[derive(Config, Debug)]
pub struct TrainingConfig {
    pub model: ModelConfig,
    pub optimizer: AdamConfig,
    #[config(default = 10)]
    pub num_epochs: usize,
    #[config(default = 64)]
    pub batch_size: usize,
    #[config(default = 4)]
    pub num_workers: usize,
    #[config(default = 42)]
    pub seed: u64,
    #[config(default = 1.0e-4)]
    pub learning_rate: f64,
}

fn create_artifact_dir(artifact_dir: &str) {
    // åœ¨è·å–å‡†ç¡®çš„å­¦ä¹ å™¨æ‘˜è¦ä¹‹å‰ç§»é™¤ç°æœ‰å·¥ä»¶
    std::fs::remove_dir_all(artifact_dir).ok();
    std::fs::create_dir_all(artifact_dir).ok();
}

pub fn train<B: AutodiffBackend>(artifact_dir: &str, config: TrainingConfig, device: B::Device) {
    create_artifact_dir(artifact_dir);
    config
        .save(format!("{artifact_dir}/config.json"))
        .expect("Config should be saved successfully");

    B::seed(&device, config.seed);

    let batcher = MnistBatcher::default();

    let dataloader_train = DataLoaderBuilder::new(batcher.clone())
        .batch_size(config.batch_size)
        .shuffle(config.seed)
        .num_workers(config.num_workers)
        .build(MnistDataset::train());

    let dataloader_test = DataLoaderBuilder::new(batcher)
        .batch_size(config.batch_size)
        .shuffle(config.seed)
        .num_workers(config.num_workers)
        .build(MnistDataset::test());

    let learner = LearnerBuilder::new(artifact_dir)
        .metric_train_numeric(AccuracyMetric::new())
        .metric_valid_numeric(AccuracyMetric::new())
        .metric_train_numeric(LossMetric::new())
        .metric_valid_numeric(LossMetric::new())
        .with_file_checkpointer(CompactRecorder::new())
        .learning_strategy(LearningStrategy::SingleDevice(device.clone()))
        .num_epochs(config.num_epochs)
        .summary()
        .build(
            config.model.init::<B>(&device),
            config.optimizer.init(),
            config.learning_rate,
        );

    let result = learner.fit(dataloader_train, dataloader_test);

    result
        .model
        .save_file(format!("{artifact_dir}/model"), &CompactRecorder::new())
        .expect("Trained model should be saved successfully");
}
```

ä½¿ç”¨ `Config` derive åˆ›å»ºå®éªŒé…ç½®æ˜¯ä¸€ä¸ªå¥½ä¹ æƒ¯ã€‚åœ¨ `train` å‡½æ•°ä¸­ï¼Œæˆ‘ä»¬é¦–å…ˆåšçš„æ˜¯ç¡®ä¿ `artifact_dir` å­˜åœ¨ï¼Œä½¿ç”¨æ ‡å‡† rust åº“è¿›è¡Œæ–‡ä»¶æ“ä½œã€‚æ‰€æœ‰æ£€æŸ¥ç‚¹ã€æ—¥å¿—è®°å½•å’ŒæŒ‡æ ‡éƒ½å°†å­˜å‚¨åœ¨æ­¤ç›®å½•ä¸‹ã€‚æˆ‘ä»¬ä½¿ç”¨ä¹‹å‰åˆ›å»ºçš„æ‰¹å¤„ç†å™¨åˆå§‹åŒ–æ•°æ®åŠ è½½å™¨ã€‚ç”±äºéªŒè¯é˜¶æ®µä¸éœ€è¦è‡ªåŠ¨å¾®åˆ†ï¼Œ`learner.fit(...)` æ–¹æ³•å®šä¹‰äº†æ•°æ®åŠ è½½å™¨å¿…è¦çš„åç«¯çº¦æŸ `B::InnerBackend`ï¼ˆå‚è§[åç«¯](./backend.html)ï¼‰ã€‚è‡ªåŠ¨å¾®åˆ†åŠŸèƒ½é€šè¿‡ç±»å‹ç³»ç»Ÿå¯ç”¨ï¼Œä½¿å¾—å‡ ä¹ä¸å¯èƒ½å¿˜è®°æ¿€æ´»æ¢¯åº¦è®¡ç®—ã€‚

æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬åˆ›å»ºå­¦ä¹ å™¨ï¼Œåœ¨è®­ç»ƒå’ŒéªŒè¯æ­¥éª¤ä¸Šéƒ½é…ç½®å‡†ç¡®ç‡å’ŒæŸå¤±æŒ‡æ ‡ï¼Œä»¥åŠè®¾å¤‡å’Œè½®æ¬¡ã€‚æˆ‘ä»¬è¿˜ä½¿ç”¨ `CompactRecorder` é…ç½®æ£€æŸ¥æŒ‡é’ˆæ¥æŒ‡ç¤ºæƒé‡åº”å¦‚ä½•å­˜å‚¨ã€‚æ­¤ç»“æ„ä½“å®ç°äº† `Recorder` traitï¼Œä½¿å…¶èƒ½å¤Ÿä¿å­˜è®°å½•ä»¥å®ç°æŒä¹…æ€§ã€‚

ç„¶åæˆ‘ä»¬ä½¿ç”¨æ¨¡å‹ã€ä¼˜åŒ–å™¨å’Œå­¦ä¹ ç‡æ„å»ºå­¦ä¹ å™¨ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œbuild å‡½æ•°çš„ç¬¬ä¸‰ä¸ªå‚æ•°å®é™…ä¸Šåº”è¯¥æ˜¯å­¦ä¹ ç‡*è°ƒåº¦å™¨*ã€‚å½“ä»¥æµ®ç‚¹æ•°å½¢å¼æä¾›æ—¶ï¼Œå¦‚æˆ‘ä»¬çš„ç¤ºä¾‹ä¸­ï¼Œå®ƒä¼šè‡ªåŠ¨è½¬æ¢ä¸º*æ’å®š*å­¦ä¹ ç‡è°ƒåº¦å™¨ã€‚å­¦ä¹ ç‡ä¸æ˜¯ä¼˜åŒ–å™¨é…ç½®çš„ä¸€éƒ¨åˆ†ï¼Œå› ä¸ºå…¶ä»–æ¡†æ¶ä¸­ç»å¸¸è¿™æ ·åšï¼Œè€Œæ˜¯åœ¨æ‰§è¡Œä¼˜åŒ–å™¨æ­¥éª¤æ—¶ä½œä¸ºå‚æ•°ä¼ é€’ã€‚è¿™é¿å…äº†å¿…é¡»æ”¹å˜ä¼˜åŒ–å™¨çŠ¶æ€ï¼Œå› æ­¤æ›´åŠ å‡½æ•°åŒ–ã€‚åœ¨ä½¿ç”¨å­¦ä¹ å™¨ç»“æ„æ—¶æ²¡æœ‰åŒºåˆ«ï¼Œä½†å¦‚æœæ‚¨å®ç°è‡ªå·±çš„è®­ç»ƒå¾ªç¯ï¼Œè¿™å°†æ˜¯ä¸€ä¸ªéœ€è¦æŒæ¡çš„åŸºæœ¬ç»†å¾®å·®åˆ«ã€‚

ä¸€æ—¦å­¦ä¹ å™¨åˆ›å»ºå®Œæˆï¼Œæˆ‘ä»¬å¯ä»¥ç®€å•åœ°è°ƒç”¨ `fit()` å¹¶æä¾›è®­ç»ƒå’ŒéªŒè¯æ•°æ®åŠ è½½å™¨ã€‚ä¸ºäº†ç®€å•èµ·è§ï¼Œåœ¨æ­¤ç¤ºä¾‹ä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨æµ‹è¯•é›†ä½œä¸ºéªŒè¯é›†ï¼›ä½†æ˜¯ï¼Œæˆ‘ä»¬ä¸å»ºè®®åœ¨å®é™…ä½¿ç”¨ä¸­è¿™æ ·åšã€‚

æœ€åï¼Œè®­ç»ƒçš„æ¨¡å‹ç”± `fit()` æ–¹æ³•è¿”å›ã€‚ç„¶åä½¿ç”¨ `CompactRecorder` ä¿å­˜è®­ç»ƒçš„æƒé‡ã€‚æ­¤è®°å½•å™¨ä½¿ç”¨ `MessagePack` æ ¼å¼ï¼Œæµ®ç‚¹æ•°ä½¿ç”¨åŠç²¾åº¦ `f16`ï¼Œæ•´æ•°ä½¿ç”¨ `i16`ã€‚å…¶ä»–è®°å½•å™¨å¯ç”¨ï¼Œæä¾›å¯¹å„ç§æ ¼å¼çš„æ”¯æŒï¼Œå¦‚ `BinCode` å’Œ `JSON`ï¼Œå¸¦æˆ–ä¸å¸¦å‹ç¼©ã€‚ä»»ä½•åç«¯ï¼Œæ— è®ºç²¾åº¦å¦‚ä½•ï¼Œéƒ½å¯ä»¥åŠ è½½ä»»ä½•ç±»å‹çš„è®°å½•æ•°æ®ã€‚

---

*æœ¬æ–‡æ¡£ç¿»è¯‘è‡ª Burn å®˜æ–¹æ–‡æ¡£ï¼šhttps://burn.dev/books/burn/basic-workflow/training.html*
