# 推理 (Inference)

现在我们已经训练了模型，下一步自然是使用它进行推理。

您需要两样东西来为模型加载权重：模型的记录和模型的配置。由于 Burn 中的参数是惰性初始化的，`ModelConfig::init` 函数不会执行任何分配和 GPU/CPU 内核。权重在首次使用时初始化，因此您可以安全地使用 `config.init(device).load_record(record)` 而没有任何有意义的性能成本。让我们在新文件 `src/inference.rs` 中创建一个简单的 `infer` 方法，我们将用它来加载我们训练好的模型。

```rust
use crate::{data::MnistBatcher, training::TrainingConfig};
use burn::{
    data::{dataloader::batcher::Batcher, dataset::vision::MnistItem},
    prelude::*,
    record::{CompactRecorder, Recorder},
};

pub fn infer<B: Backend>(artifact_dir: &str, device: B::Device, item: MnistItem) {
    let config = TrainingConfig::load(format!("{artifact_dir}/config.json"))
        .expect("Config should exist for model; run train first");
    let record = CompactRecorder::new()
        .load(format!("{artifact_dir}/model").into(), &device)
        .expect("Trained model should exist; run train first");

    let model = config.model.init::<B>(&device).load_record(record);

    let label = item.label;
    let batcher = MnistBatcher::default();
    let batch = batcher.batch(vec![item], &device);
    let output = model.forward(batch.images);
    let predicted = output.argmax(1).flatten::<1>(0, 1).into_scalar();

    println!("Predicted {predicted} Expected {label}");
}
```

第一步是加载训练配置以获取正确的模型配置。然后我们可以使用与训练期间相同的记录器来获取记录。最后我们可以使用配置和记录初始化模型。为了简单起见，我们可以使用训练期间使用的相同批处理器来将 MnistItem 传递给张量。

通过运行推理函数，您应该看到模型的预测！

在 `main.rs` 文件中的 `train` 函数调用后添加对 `infer` 的调用：

```rust
#![recursion_limit = "256"]
mod data;
mod inference;
mod model;
mod training;

use crate::{model::ModelConfig, training::TrainingConfig};
use burn::{
    backend::{Autodiff, Wgpu},
    data::dataset::Dataset,
    optim::AdamConfig,
};

fn main() {
    type MyBackend = Wgpu<f32, i32>;
    type MyAutodiffBackend = Autodiff<MyBackend>;

    let device = burn::backend::wgpu::WgpuDevice::default();
    let artifact_dir = "/tmp/guide";
    crate::training::train::<MyAutodiffBackend>(
        artifact_dir,
        TrainingConfig::new(ModelConfig::new(10, 512), AdamConfig::new()),
        device.clone(),
    );
    crate::inference::infer::<MyBackend>(
        artifact_dir,
        device,
        burn::data::dataset::vision::MnistDataset::test()
            .get(42)
            .unwrap(),
    );
}
```

数字 `42` 是 MNIST 数据集中图像的索引。您可以使用这个 <a href="https://observablehq.com/@davidalber/mnist-viewer">MNIST 查看器</a> 来探索和验证它们。

<hr />

在这个简短指南中，我们向您介绍了使用 Burn 入门的基本构建块。虽然还有很多要探索的内容，但我们的目标是为您提供在框架内启动生产力所必需的知识。

---

*本文档翻译自 Burn 官方文档：https://burn.dev/books/burn/basic-workflow/inference.html*
