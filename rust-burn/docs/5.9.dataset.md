# 数据集 (Dataset)

从核心上讲，数据集是通常与特定分析或处理任务相关的数据集合。数据模态可能因任务而异，但大多数数据集主要由图像、文本、音频或视频组成。

这个数据源代表了机器学习中成功训练模型的组成部分。因此，提供一个便捷且高性能的 API 来处理您的数据至关重要。由于这个过程在不同问题之间差异很大，它被定义为应该在您的类型上实现的 trait。数据集 trait 与 PyTorch 中的数据集抽象类非常相似：

```rust
pub trait Dataset<I>: Send + Sync {
    fn get(&self, index: usize) -> Option<I>;
    fn len(&self) -> usize;
}
```

数据集 trait 假设一个固定长度的项目集合，可以在恒定时间内随机访问。这与使用 Apache Arrow 在底层提高流式性能的数据集有主要区别。Burn 中的数据集不假设它们将如何被访问；它只是一个项目的集合。

然而，您可以组合多个数据集转换来懒惰地获得您想要的内容，无需预处理，这样您的训练可以立即开始！

## 转换 (Transformation)

Burn 中的转换都是懒惰的，并修改一个或多个输入数据集。这些转换的目标是为您提供必要的工具，以便您可以为复杂的数据分布建模。

| 转换 | 描述 |
|------|------|
| `SamplerDataset` | 从数据集中采样项目。这是将数据集建模为固定大小概率分布的便捷方式。|
| `SelectionDataset` | 通过索引从数据集中选择项目子集。可以随机打乱；可以重新打乱。|
| `ShuffledDataset` | 打乱包装的数据集；这是 `SelectionDataset` 的薄包装器。|
| `PartialDataset` | 返回指定范围内输入数据集的视图。|
| `MapperDataset` | 在输入数据集上懒惰地计算转换。|
| `ComposedDataset` | 将多个数据集组合在一起创建更大的数据集，而不复制任何数据。|
| `WindowsDataset` | 设计用于处理从输入数据集提取的重叠数据窗口。|

让我们看看每种数据集转换的基本用法以及它们如何组合在一起。这些转换默认是懒惰的，除非指定，这减少了对不必要的中间分配的需求并提高了性能。每个转换的完整文档可以在 [API 参考](https://burn.dev/docs/burn/data/dataset/transform/index.html) 中找到。

- **SamplerDataset**：此转换可用于从数据集中有（默认）或无放回地采样项目。转换使用采样大小初始化，该大小可以大于或小于输入数据集大小。这在以下情况下特别有用：我们希望在训练期间更频繁地检查点较大的数据集，而不太频繁地检查点较小的数据集，因为轮次的大小现在由采样大小控制。使用示例：

```rust
type DbPedia = SqliteDataset<DbPediaItem>;
let dataset: DbPedia = HuggingfaceDatasetLoader::new("dbpedia_14")
        .dataset("train").
        .unwrap();

let dataset = SamplerDataset<DbPedia, DbPediaItem>::new(dataset, 10000);
```

- **SelectionDataset**：此转换可用于通过索引从数据集中选择项目子集。它可以使用要从输入数据集中选择的索引列表来初始化。这在您想要从较大的数据集创建较小的数据集时特别有用，例如，从训练集创建验证集。

`SelectionDataset` 也可以使用随机种子初始化以在选择前打乱索引。这在您想要随机选择数据集项目子集时很有用。

基础数据集项目可能在选择中被包含多次。

```rust
let explicit = SelectionDataset::from_indices_checked(dataset.clone(), vec![0, 1, 2, 0]);

let shuffled = SelectionDataset::new_shuffled(dataset.clone(), &mut rng);
let shuffled = SelectionDataset::new_shuffled(dataset.clone(), 42);

let mut mutable = SelectionDataset::new_select_all(dataset.clone(), vec![0, 1, 2, 0]);
mutable.shuffle(42);
mutable.shuffle(&mut rng);
```

- **ShuffledDataset**：此转换是 `SelectionDataset` 的薄包装器，用于打乱包装的数据集。

- **PartialDataset**：此转换返回指定范围内输入数据集的视图。

- **ComposedDataset**：此转换将多个数据集组合在一起创建更大的数据集，而不复制任何数据。

- **WindowsDataset**：此转换设计用于处理从输入数据集提取的重叠数据窗口。

## MNIST 数据集实现示例

以下是 MNIST 数据集实现的完整示例，展示了如何创建自定义数据集：

```rust
/// 原始 MNIST 项目，图像以字节向量形式表示。
pub struct MnistItemRaw {
    /// 图像字节。
    pub image_bytes: Vec<u8>,

    /// 图像标签。
    pub label: u8,
}

/// MNIST 项目，图像以二维浮点数组形式表示。
pub struct MnistItem {
    /// 作为二维浮点数组的图像。
    pub image: [[f32; WIDTH]; HEIGHT],

    /// 图像标签。
    pub label: u8,
}

struct BytesToImage;

impl Mapper<MnistItemRaw, MnistItem> for BytesToImage {
    /// 将原始 MNIST 项目（图像字节）转换为 MNIST 项目（二维数组图像）。
    fn map(&self, item: &MnistItemRaw) -> MnistItem {
        // 确保图像尺寸正确。
        debug_assert_eq!(item.image_bytes.len(), WIDTH * HEIGHT);

        // 将图像转换为二维浮点数组。
        let mut image_array = [[0f32; WIDTH]; HEIGHT];
        for (i, pixel) in item.image_bytes.iter().enumerate() {
            let x = i % WIDTH;
            let y = i / HEIGHT;
            image_array[y][x] = *pixel as f32;
        }

        MnistItem {
            image: image_array,
            label: item.label,
        }
    }
}

type MappedDataset = MapperDataset<InMemDataset<MnistItemRaw>, BytesToImage, MnistItemRaw>;

/// MNIST 数据集包含 70,000 张 28x28 黑白图像，分为 10 个类别（每个数字一个），每个类别 7,000 张图像。
/// 有 60,000 张训练图像和 10,000 张测试图像。
///
/// 数据从 [CVDF 镜像](https://github.com/cvdfoundation/mnist) 下载。
pub struct MnistDataset {
    dataset: MappedDataset,
}
```

要构造 `MnistDataset`，数据源必须解析为预期的 `MappedDataset` 类型。由于训练集和测试集使用相同的文件格式，我们可以分离功能来加载 `train()` 和 `test()` 数据集。

```rust
impl MnistDataset {
    /// 创建新的训练数据集。
    pub fn train() -> Self {
        Self::new("train")
    }

    /// 创建新的测试数据集。
    pub fn test() -> Self {
        Self::new("test")
    }

    fn new(split: &str) -> Self {
        // 下载数据集
        let root = MnistDataset::download(split);

        // 将数据解析为图像字节向量和标签向量
        let images: Vec<Vec<u8>> = MnistDataset::read_images(&root, split);
        let labels: Vec<u8> = MnistDataset::read_labels(&root, split);

        // 收集为 MnistItemRaw 向量
        let items: Vec<_> = images
            .into_iter()
            .zip(labels)
            .map(|(image_bytes, label)| MnistItemRaw { image_bytes, label })
            .collect();

        // 为 InMemDataset<MnistItemRaw> 创建 MapperDataset 来转换
        // 项目 (MnistItemRaw -> MnistItem)
        let dataset = InMemDataset::new(items);
        let dataset = MapperDataset::new(dataset, BytesToImage);

        Self { dataset }
    }

    /// 从网络下载 MNIST 数据集文件。
    /// 如果下载无法完成或文件内容无法写入磁盘，则会 panic。
    fn download(split: &str) -> PathBuf {
        // 数据集文件存储在 burn-dataset 缓存目录中
        let cache_dir = dirs::home_dir()
            .expect("Could not get home directory")
            .join(".cache")
            .join("burn-dataset");
        let split_dir = cache_dir.join("mnist").join(split);

        if !split_dir.exists() {
            create_dir_all(&split_dir).expect("Failed to create base directory");
        }

        // 下载分割文件
        match split {
            "train" => {
                MnistDataset::download_file(TRAIN_IMAGES, &split_dir);
                MnistDataset::download_file(TRAIN_LABELS, &split_dir);
            }
            "test" => {
                MnistDataset::download_file(TEST_IMAGES, &split_dir);
                MnistDataset::download_file(TEST_LABELS, &split_dir);
            }
            _ => panic!("Invalid split specified {}", split),
        };

        split_dir
    }

    /// 从 MNIST 数据集 URL 下载文件到目标目录。
    /// 文件下载进度通过[进度条](indicatif)报告。
    fn download_file<P: AsRef<Path>>(name: &str, dest_dir: &P) -> PathBuf {
        // 输出文件名
        let file_name = dest_dir.as_ref().join(name);

        if !file_name.exists() {
            // 下载 gzip 文件
            let bytes = download_file_as_bytes(&format!("{URL}{name}.gz"), name);

            // 创建文件以写入下载的内容
            let mut output_file = File::create(&file_name).unwrap();

            // 解码 gzip 文件内容并写入磁盘
            let mut gz_buffer = GzDecoder::new(&bytes[..]);
            std::io::copy(&mut gz_buffer, &mut output_file).unwrap();
        }

        file_name
    }

    /// 在提供的路径读取指定分割的图像。
    /// 每个图像是一个字节向量。
    fn read_images<P: AsRef<Path>>(root: &P, split: &str) -> Vec<Vec<u8>> {
        let file_name = if split == "train" {
            TRAIN_IMAGES
        } else {
            TEST_IMAGES
        };
        let file_name = root.as_ref().join(file_name);

        // 从 16 字节头部元数据读取图像数量
        let mut f = File::open(file_name).unwrap();
        let mut buf = [0u8; 4];
        let _ = f.seek(SeekFrom::Start(4)).unwrap();
        f.read_exact(&mut buf)
            .expect("Should be able to read image file header");
        let size = u32::from_be_bytes(buf);

        let mut buf_images: Vec<u8> = vec![0u8; WIDTH * HEIGHT * (size as usize)];
        let _ = f.seek(SeekFrom::Start(16)).unwrap();
        f.read_exact(&mut buf_images)
            .expect("Should be able to read image file header");

        buf_images
            .chunks(WIDTH * HEIGHT)
            .map(|chunk| chunk.to_vec())
            .collect()
    }

    /// 在提供的路径读取指定分割的标签。
    fn read_labels<P: AsRef<Path>>(root: &P, split: &str) -> Vec<u8> {
        let file_name = if split == "train" {
            TRAIN_LABELS
        } else {
            TEST_LABELS
        };
        let file_name = root.as_ref().join(file_name);

        // 从 8 字节头部元数据读取标签数量
        let mut f = File::open(file_name).unwrap();
        let mut buf = [0u8; 4];
        let _ = f.seek(SeekFrom::Start(4)).unwrap();
        f.read_exact(&mut buf)
            .expect("Should be able to read label file header");
        let size = u32::from_be_bytes(buf);

        let mut buf_labels: Vec<u8> = vec![0u8; size as usize];
        let _ = f.seek(SeekFrom::Start(8)).unwrap();
        f.read_exact(&mut buf_labels)
            .expect("Should be able to read labels from file");

        buf_labels
    }
}
```

由于 `MnistDataset` 只是包装了一个带有 `InMemDataset` 的 `MapperDataset` 实例，我们可以轻松实现 `Dataset` trait。

```rust
impl Dataset<MnistItem> for MnistDataset {
    fn get(&self, index: usize) -> Option<MnistItem> {
        self.dataset.get(index)
    }

    fn len(&self) -> usize {
        self.dataset.len()
    }
}
```

现在唯一缺少的是 `Batcher`，我们已经在[基本工作流指南](../basic-workflow/data.html)中介绍过。`Batcher` 接受由数据加载器检索的 `MnistItem` 列表作为输入，并返回一批图像作为三维张量及其目标。

---

*本文档翻译自 Burn 官方文档：https://burn.dev/books/burn/building-blocks/dataset.html*
