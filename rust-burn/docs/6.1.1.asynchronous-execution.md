# 异步执行 (Asynchronous Execution)

大多数 Burn 后端以异步方式执行张量操作。然而，对于大多数张量操作，通常不需要异步表示法，优先考虑同步 Rust 的简单性。

只有少数操作会触发后端的同步，正确处理这些操作以优化硬件利用率非常重要。这些操作是 `into_data`、`into_scalar` 和 `sync`。某些张量操作可能在底层调用 `into_data`，从而触发同步，例如某些后端的 `to_device`。

有几种方法可以最小化同步开销，其中之一是将同步操作批处理为单个事务。Burn 提供了一个高级可组合 API 来构建事务，这只会触发设备上的单次同步。

例如，在训练期间收集指标时经常使用：

```rust
/// 所有这些变量都是张量。
let (output, loss, targets) = ..;

/// 现在 output、loss 和 targets 将是存储在 CPU 上的 `TensorData`。
let [output, loss, targets] = Transaction::default()
    .register(output)
    .register(loss)
    .register(targets)
    .execute()
    .try_into()
    .expect("Correct amount of tensor data");
```

另一种优化读取和避免设备停滞的方法是在不同线程上读取数据。在底层，基于 CubeCL 的后端为不同线程分配不同的执行队列，这意味着同步一个线程不应该影响另一个线程的吞吐量。

## 为不同任务使用不同后端

张量操作不是唯一异步的东西；数据集和数据加载也是惰性执行的。这允许高效的数据增强和采样，而无需在磁盘上缓存大型数据集。然而，如果数据增强在与训练相同的设备上执行，这可能会降低训练吞吐量。因此，通常鼓励为此目的使用不同的设备，甚至是不同的后端。为了获得最佳性能，还要避免小分配后跟批处理过程。即使它不会破坏异步性，也可能减慢性能。

```rust
/// Items 是许多张量的向量。
let items = ..;
let batch = Tensor::cat(items, 1);
```

倾向于在数据增强设备上而不是在训练设备上进行张量连接。

```rust
/// Items 是许多张量的向量。
let items = ..;
let device_training = ..;
let axis_batch = 0;

let items = Tensor::cat(items, axis_batch);
let batch = Tensor::from_data(items.into_data(), device_training);
```

---

*本文档翻译自 Burn 官方文档：https://burn.dev/books/burn/performance/good-practices/asynchronous-execution.html*
