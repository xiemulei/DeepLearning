# 内核融合 (Kernel Fusion)

异步执行的一个有趣特性是它允许像内核融合这样的性能优化。结合 CubeCL 和其即时编译器，Burn 可以将张量操作序列化为符号图，然后优化它以提高效率。

内核融合可能会重新排序操作以减少全局内存读取、写入和分配。了解哪些操作可以融合是相关的，因为很容易破坏执行图。

优化融合的最简单方法是避免张量存活时间过长。当融合不可能时，所有稍后将使用的张量都会触发全局内存写入。幸运的是，Rust 和 Clippy 在检测不必要的克隆方面做得很好，但仍应特别小心。

视图操作也会干扰融合。它们可以包含在优化的图中，但仅在一定程度上，并且它们降低了向量化潜力，因为我们对转换索引的内存访问模式有更少的保证。因此，在执行操作块之前将视图操作分组在一起是一个好习惯。

```rust
let tensor4 = tensor1.unsqueeze().matmul(tensor2) + tensor3.unsqueeze();
```

可以用以下方式改进：

```rust
let tensor1 = tensor1.unsqueeze();
let tensor3 = tensor3.unsqueeze();
let tensor4 = tensor1.matmul(tensor2) + tensor3;
```

这减少了必要的重新排序，并且可能减少全局内存写入或改善向量化。我们将来可能能够检测这些模式，但现在，使用这种模式排序您的操作是个好主意。提醒一下，视图操作通常在大多数情况下只更新张量元数据。这些操作包括 `slice`、`slice_assign`、`select`、`gather`、`scatter`、`reshape`、`swap_dims`、`transpose`、`unsqueeze` 等。

启用融合后，通常不需要编写自定义内核，因为您可以依赖我们的系统来优化大多数逐元素操作。然而，大多数计算密集型内核需要许多技巧和对 GPU 内存架构的深入了解，在这些情况下，自动编译器优化通常不如人工设计的算法。这就是为什么 Burn 的融合方法以读取时融合和写入时融合为中心。这意味着改变张量形状的复杂计算密集型内核可以在读取输入张量和写入输出张量时融合一块逐元素操作。这意味着一系列中的多个计算密集型操作可能会降低融合潜力。

```rust
// 如果 tensor1 和 tensor2 是抽象张量，这行可能触发 3 次写入：tensor1、tensor2 和 tensor3。
let tensor3 = tensor1.clone().sum_dim(tensor2.clone(), 2);
let tensor4 = tensor2.sum_dim(tensor3, 2);
let tensor5 = tensor4 + (tensor1 * tensor2);
```

```rust
let tmp = tensor1.clone() + tensor2.clone();
let tensor3 = tensor1.sum_dim(tensor2, 2);
let tensor4 = tensor2.sum_dim(tensor3, 2);
let tensor5 = tensor4 + tmp;
```

教训是什么？尽可能只将最新值传递给计算操作。不要在计算密集型操作之前克隆张量，因为如果该张量不是从初始融合物化的，它可能会触发额外的写入。

这有点复杂，但如果 `tensor1` 和 `tensor2` 在全局内存中是具体的，第一个代码片段实际上更好。如果 `tensor1` 和 `tensor2` 是模型参数，就是这种情况，因此在这种情况下更喜欢这种实现风格。

当 `tensor1` 和 `tensor2` 是虚拟张量时，更喜欢第二个代码片段，这意味着它们被之前的操作融合，需要全局内存读取才能稍后访问。如果这些张量是神经网络中信号的一部分，就会发生这种情况。

在这种情况下重新排序操作可能有帮助，但不会创建临时值，使之前的优化更加困难。我们最终可能会自动优化这些情况，但解决方案空间相当大，这不是计划的优化。在面临模糊情况时，分析模型块总是一个好主意，以确定哪个代码块更快。

---

*本文档翻译自 Burn 官方文档：https://burn.dev/books/burn/performance/good-practices/kernel-fusion.html*
